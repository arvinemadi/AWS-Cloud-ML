{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of AWS training and model endpoint deployment\n",
    "\n",
    "This example main points:\n",
    "- Using AWS Sagemaker available models for training\n",
    "- Deploying the trained model \n",
    "- Inference from the deployed model\n",
    "\n",
    "Dataset: Many useful available datasets can be used from E-commerce's review at [Link](https://www.kaggle.com/code/u601372/e-commerce-s-review/data?select=Toys_and_Games_5.json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.serializers import JSONSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparations\n",
    "\n",
    "When using the Sagemaker, the data cannot be stored locally and it has to be stored on a S3 bucket. We can unzip and store the unzipped version on S3. Or we can have function for it that can become useful in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_data(input_data_path):\n",
    "    with zipfile.ZipFile(input_data_path, 'r') as input_data_zip:\n",
    "        input_data_zip.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of each entry in the dataset in a Jason format is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"root\":{9 items\n",
    "    #\"reviewerID\":string\"A1VXOAVRGKGEAK\"\n",
    "    #\"asin\":string\"0439893577\"\n",
    "    #\"reviewerName\":string\"Angie\"\n",
    "    #\"helpful\":[2 items\n",
    "            #0:int0\n",
    "            #1:int0\n",
    "    #]\n",
    "    #\"reviewText\":string\"I like the item pricing. My granddaughter wanted to mark on it but I wanted it just for the letters.\"\n",
    "    #\"overall\":int5\n",
    "    #\"summary\":string\"Magnetic board\"\n",
    "    #\"unixReviewTime\":int1390953600\n",
    "    #\"reviewTime\":string\"01 29, 2014\"\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data consists of reviews texts and their counts of upvotes (helpful) and total votes. We want a model to predict if a review (text) is helpful or not. \n",
    "\n",
    "From the training dataset we can create labels for each text. If the review has any votes, the review is helpful if at least 50% of the total votes mark it as helpful.\n",
    "\n",
    "The function below assigned labels to the data and returns labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(input_data):\n",
    "    labeled_data = []\n",
    "    HELPFUL_LABEL = \"__label__1\"\n",
    "    UNHELPFUL_LABEL = \"__label__2\"\n",
    "     \n",
    "    for l in open(input_data, 'r'):\n",
    "        l_object = json.loads(l)\n",
    "        helpful_votes = float(l_object['helpful'][0])\n",
    "        total_votes = l_object['helpful'][1]\n",
    "        reviewText = l_object['reviewText']\n",
    "        if total_votes != 0:\n",
    "            if helpful_votes / total_votes >= .5:\n",
    "                labeled_data.append(\" \".join([HELPFUL_LABEL, reviewText]))\n",
    "            elif helpful_votes / total_votes < .5:\n",
    "                labeled_data.append(\" \".join([UNHELPFUL_LABEL, reviewText]))\n",
    "          \n",
    "    return labeled_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each review could be long and consist of several sentences. We can create more training data by splitting the sentences and assigning the review sentence of all of its sentences. It may not be the most optimum but we can try and revise later if needed. There are many language models that can take long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(labeled_data):\n",
    "    split_sentences = []\n",
    "    n_positive = 0\n",
    "    n_negative = 0\n",
    "    for d in labeled_data:\n",
    "        label = d.split()[0]        \n",
    "        sentences = \" \".join(d.split()[1:]).split(\".\") # Initially split to separate label, then separate sentences\n",
    "        for s in sentences:\n",
    "            if s: # Make sure sentences isn't empty. Common w/ \"...\"\n",
    "                split_sentences.append(\" \".join([label, s]))\n",
    "                if label == \"__label__1\":\n",
    "                    n_positive += 1\n",
    "                else:\n",
    "                    n_negative += 1\n",
    "                \n",
    "    print(\"Number of positive samples:{}\".format(n_positive))\n",
    "    print(\"Number of negative samples:{}\".format(n_negative))\n",
    "    return split_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above functions we can process the raw data and create our training data and visulaize some of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples:450187\n",
      "Number of negative samples:72205\n",
      "['__label__1 Love the magnet easel', '__label__1  great for moving to different areas', '__label__1  Wish it had some sort of non skid pad on bottom though', '__label__1 Both sides are magnetic', \"__label__1  A real plus when you're entertaining more than one child\", '__label__1  The four-year old can find the letters for the words, while the two-year old can find the pictures the words spell', '__label__1  (I bought letters and magnetic pictures to go with this board)', '__label__1  Both grandkids liked it a lot, which means I like it a lot as well', '__label__1  Have not even introduced markers, as this will be used strictly as a magnetic board']\n"
     ]
    }
   ],
   "source": [
    "input_data  = unzip_data('Toys_and_Games_5.json.zip')\n",
    "labeled_data = label_data('Toys_and_Games_5.json')\n",
    "split_sentence_data = split_sentences(labeled_data)\n",
    "\n",
    "print(split_sentence_data[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that our data is unbalanced and only 17% of the data has negatives samples. Even if the model gives positive label for all of the inputs it would create >82% accuracy on the training. Althought the goal of this notebook is to show AWS Sagemaker, in reality we need to be careful about this when setting up the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data\n",
    "\n",
    "We loaded the data from a S3 address and did processing on it and labeled it. To be able to use the data on Sagemaker, we need to store the processed data back into a S3 location.\n",
    "\n",
    "Each sagemaker session has a default or assigned S3 bucket that can be found by using the following methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "BUCKET = sess.default_bucket()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a prefix (S3 sub directory) for the location of the data we want to store.\n",
    "\n",
    "Also we set a pivot point to split the data. The first 90% of the data are assigned to the training set and the rest of 10% to the test. In reality we need to check the dataset to make sure that labels are randomly spread across the initial raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file written!\n",
      "Validation file written!\n",
      "Train file uploaded!\n",
      "Validation file uploaded!\n",
      "hello_blaze_train hello_blaze_validation\n"
     ]
    }
   ],
   "source": [
    "def cycle_data(fp, data):\n",
    "    for d in data:\n",
    "        fp.write(d + \"\\n\")\n",
    "\n",
    "def write_trainfile(split_sentence_data):\n",
    "    train_path = \"hello_blaze_train\"\n",
    "    with open(train_path, 'w') as f:\n",
    "        cycle_data(f, split_sentence_data)\n",
    "    return train_path\n",
    "\n",
    "def write_validationfile(split_sentence_data):\n",
    "    validation_path = \"hello_blaze_validation\"\n",
    "    with open(validation_path, 'w') as f:\n",
    "        cycle_data(f, split_sentence_data)\n",
    "    return validation_path \n",
    "\n",
    "def upload_file_to_s3(file_name, s3_prefix):\n",
    "    object_name = os.path.join(s3_prefix, file_name)\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, BUCKET, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "\n",
    "s3_prefix = \"Aug2022\"\n",
    "\n",
    "split_data_trainlen = int(len(split_sentence_data) * .9)\n",
    "split_data_validationlen = int(len(split_sentence_data) * .1)\n",
    "\n",
    "\n",
    "train_path = write_trainfile(split_sentence_data[:split_data_trainlen])\n",
    "print(\"Training file written!\")\n",
    "validation_path = write_validationfile(split_sentence_data[split_data_trainlen:])\n",
    "print(\"Validation file written!\")\n",
    "\n",
    "upload_file_to_s3(train_path, s3_prefix)\n",
    "print(\"Train file uploaded!\")\n",
    "upload_file_to_s3(validation_path, s3_prefix)\n",
    "print(\"Validation file uploaded!\")\n",
    "\n",
    "print(\" \".join([train_path, validation_path]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where it gets finally interesting.\n",
    "\n",
    "AWS has a collection of models that can be used. These are saved as docker images. To find the container URI the function [image_uris](https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html) is used that return the URI based on the framework argument that is passed to it. There are other parameters to return the URI based on geographical location and version etc.\n",
    "\n",
    "The available frameworks can be found at: [Frameworks](https://docs.aws.amazon.com/sagemaker/latest/dg/ecr-us-east-2.html). A lot of possibilities!\n",
    "\n",
    "And we are going to use the [blazing text](https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html).\n",
    "\n",
    "Believe it or not, you're already almost done! Part of the appeal of SageMaker is that AWS has already done the heavy implementation lifting for you. Launch a \"BlazingText\" training job from the SageMaker console. You can do so by searching \"SageMaker\", and navigating to Training Jobs on the left hand side. After selecting \"Create Training Job\", perform the following steps:\n",
    "* Select \"BlazingText\" from the algorithms available. \n",
    "* Specify the \"file\" input mode of training. \n",
    "* Under \"resource configuration\", select the \"ml.m5.large\" instance type. Specify 5 additional GBs of memory. \n",
    "* Set a stopping condition for 15 minutes. \n",
    "* Under hyperparameters, set \"mode\" to \"supervised\"\n",
    "* Under input_data configuration, input the S3 path to your training and validation datasets under the \"train\" and \"validation\" channels. You will need to create a channel named \"validation\".  \n",
    "* Specify an output path in the same bucket that you uploaded training and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "container = image_uris.retrieve(\"blazingtext\", sess.boto_region_name, \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do a training job we need to set up an Estimator. An estimator in principle defines the instance to run the training job and the location of the output of the model, and also how long to run the model.\n",
    "\n",
    "The hyperparameters, that are specific to the model to be used are passed as an argument when defining the Estimator or it can be later set by using the set_hyperparameters method as used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "blazingtext = sagemaker.estimator.Estimator(container,\n",
    "                                           role,\n",
    "                                           instance_count=1,\n",
    "                                           instance_type='ml.m4.xlarge',\n",
    "                                           output_path='s3://{}/{}/output'.format(BUCKET, s3_prefix),\n",
    "                                           sagemaker_session = sess,\n",
    "                                           max_run=360000,\n",
    "                                           )\n",
    "\n",
    "blazingtext.set_hyperparameters(mode = 'supervised',\n",
    "                                #epochs = 5,\n",
    "                                #min_count = 5,\n",
    "                                early_stopping = True,\n",
    "                                negative_samples = 6,\n",
    "                                batch_size = 11,\n",
    "                                patience = 4,\n",
    "                                #learning_rate = 0.05,\n",
    "                                vector_dim = 10,\n",
    "                                #sampling_threshold = 0.0001,\n",
    "                                min_epochs = 5,\n",
    "                                #word_ngrams = 3,\n",
    "                                ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the data loaders\n",
    "\n",
    "Need to pass the location of the stored training and validation datasets and the format of the data that is specific to the model that is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-564698410651/Aug2022/hello_blaze_train\n",
      "s3://sagemaker-us-east-1-564698410651/Aug2022/hello_blaze_validation\n"
     ]
    }
   ],
   "source": [
    "train_full_path = 's3://{}/{}/'.format(BUCKET, s3_prefix) + train_path\n",
    "print(train_full_path)\n",
    "validation_full_path = 's3://{}/{}/'.format(BUCKET, s3_prefix) + validation_path\n",
    "print(validation_full_path)\n",
    "\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    train_full_path,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    validation_full_path,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "We trained the model by using the fit method of the Estimator. \n",
    "\n",
    "When iniiating the training, first an instance is setup based on the parameter set in the Estimator definition. That can take a little bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-15 14:51:48 Starting - Starting the training job...\n",
      "2022-08-15 14:52:14 Starting - Preparing the instances for trainingProfilerReport-1660575108: InProgress\n",
      ".........\n",
      "2022-08-15 14:53:42 Downloading - Downloading input data...\n",
      "2022-08-15 14:54:18 Training - Downloading the training image...\n",
      "2022-08-15 14:54:44 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[08/15/2022 14:54:47 WARNING 140628294846272] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[08/15/2022 14:54:47 WARNING 140628294846272] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[08/15/2022 14:54:47 INFO 140628294846272] nvidia-smi took: 0.025272846221923828 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/15/2022 14:54:47 INFO 140628294846272] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[08/15/2022 14:54:47 INFO 140628294846272] Processing /opt/ml/input/data/train/hello_blaze_train . File size: 44.97289848327637 MB\u001b[0m\n",
      "\u001b[34m[08/15/2022 14:54:47 INFO 140628294846272] Processing /opt/ml/input/data/validation/hello_blaze_validation . File size: 5.058439254760742 MB\u001b[0m\n",
      "\u001b[34mRead 8M words\u001b[0m\n",
      "\u001b[34mNumber of words:  35179\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/hello_blaze_validation\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0467  Progress: 6.65%  Million Words/sec: 6.20 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0437  Progress: 12.56%  Million Words/sec: 6.33 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0407  Progress: 18.61%  Million Words/sec: 6.43 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0377  Progress: 24.51%  Million Words/sec: 6.44 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0347  Progress: 30.57%  Million Words/sec: 6.49 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0315  Progress: 36.93%  Million Words/sec: 6.57 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0286  Progress: 42.79%  Million Words/sec: 6.79 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0256  Progress: 48.70%  Million Words/sec: 6.97 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0227  Progress: 54.53%  Million Words/sec: 7.12 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0199  Progress: 60.13%  Million Words/sec: 7.20 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0170  Progress: 66.06%  Million Words/sec: 7.32 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0141  Progress: 71.82%  Million Words/sec: 7.39 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0111  Progress: 77.72%  Million Words/sec: 7.48 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0083  Progress: 83.45%  Million Words/sec: 7.54 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0054  Progress: 89.25%  Million Words/sec: 7.59 #####\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0024  Progress: 95.27%  Million Words/sec: 7.66 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.826225\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 7.42 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 7.42\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 5.97\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.8716\u001b[0m\n",
      "\u001b[34mNumber of train examples: 470152\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.8262\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 52240\u001b[0m\n",
      "\n",
      "2022-08-15 14:55:13 Uploading - Uploading generated training model\n",
      "2022-08-15 14:55:33 Completed - Training job completed\n",
      "Training seconds: 104\n",
      "Billable seconds: 104\n"
     ]
    }
   ],
   "source": [
    "blazingtext.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint and Deployment in AWS Sagemaker\n",
    "\n",
    "How to use the model that is trained?\n",
    "\n",
    "In sagemaker the 'Endpoint' refers to a model in production. It is in principle an interface to the model and facilitates the communication between the model and the querries to it.\n",
    "\n",
    "To send the querries to the model first the model needs to be in production mode, which means to have been deployed and have compute resources assigned to its inference. Deployment is the configuration and establishment of computing resources to serve your model.\n",
    "\n",
    "Some of the features with AWS model deployment:\n",
    "- With AWS it is also possible to deploy the model at different geographical locations. That is called multi-AZ (availability zone) deployment\n",
    "- Auto-scaling: Auto-Scaling based on CloudWatch can take care of load balacning if the number of requests to the model is increased to avoid bottlenecks\n",
    "\n",
    "Endpoint is a predictor class: [Sagemaker Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html)\n",
    "\n",
    "Creating an endpoint and deploying the trained model into an instance using AWS examples:\n",
    "Again, since it is creating a new instance, it may take a little bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "review_classifier = blazingtext.deploy(initial_instance_count=1, \n",
    "                                       instance_type=\"ml.m4.xlarge\", \n",
    "                                       serializer=JSONSerializer()\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the review_classifier object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.predictor.Predictor object at 0x7f444010a210>\n"
     ]
    }
   ],
   "source": [
    "print(review_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__1\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.7189164757728577\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__1\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.8643396496772766\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "my_inputs = [\n",
    "    \"Dogs meouw at night.\",\n",
    "    \"The material is not top quality. I see it can be useful considering the cost\",\n",
    "]\n",
    "\n",
    "payload = {\"instances\": my_inputs}\n",
    "\n",
    "response = review_classifier.predict(payload)\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We see that we get label_1 for the first sentence that is most likely not a helpful review! The reason is again in the unbalanced data. Although we did oversampling of negative samples during training, we still need to do some probability calibration or change of threshold for the label. But these are not the goal of this notebook. Also probably it is better to use HuggingFace transformer based language models for these sort of text data. Will try to make another notebook using AWS [HuggingFace](https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html) framework.\n",
    "\n",
    "At the end, we should not forget to close the endpoint instance if no-one is going to use our deployed model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(review_classifier.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
